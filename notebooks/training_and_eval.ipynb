{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/03chrisk/PEFT-T5-on-CNN-dailynews/blob/main/Monkey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstractive Text Summarization with T5-small\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "    - 1.1 [Installing Dependencies](#installing-dependencies)\n",
    "    - 1.2 [Loading the model and the dataset](#loading-the-model-and-the-dataset)\n",
    "    - 1.3 [Exploratory Data Analysis](#exploratory-data-analysis)\n",
    "2. [Data Preprocessing](#data-preprocessing)\n",
    "    - 2.1 [Tokenizing the Data](#tokenizing-the-data)\n",
    "    - 2.2 [Data Collator and Removing Columns](#data-collator-and-removing-columns)\n",
    "    - 2.3 [Setting evaluation metrics for training](#setting-evaluation-metrics-for-training)\n",
    "    - 2.4 [Helper Functions](#helper-functions)\n",
    "3. [Base Model Testing](#base-model-testing)\n",
    "4. [Full Fine-Tuning](#full-fine-tuning)\n",
    "    - 4.1 [Setting up training config](#setting-up-training-config)\n",
    "    - 4.2 [Training and logging system metrics](#training-and-logging-system-metrics)\n",
    "    - 4.3 [Evaluation](#evaluation)\n",
    "5. [Parameter Efficient Fine-Tuning (PEFT)](#parameter-efficient-fine-tuning-peft)\n",
    "    - 5.1 [Setting up training and LoRa configs](#setting-up-training-and-lora-configs)\n",
    "    - 5.2 [Training and logging system metrics](#training-and-logging-system-metrics-1)\n",
    "    - 5.3 [Evaluation](#evaluation-1)\n",
    "6. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeneKO3p3nrx",
    "outputId": "f1e94335-d0c5-4f4c-8009-7d2079c0a156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home3/s5232686/.local/lib/python3.10/site-packages (4.45.2)\n",
      "Requirement already satisfied: datasets in /home3/s5232686/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: evaluate in /home3/s5232686/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: rouge_score in /home3/s5232686/.local/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: torch in /home3/s5232686/.local/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /home3/s5232686/.local/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: peft in /home3/s5232686/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: bert-score in /home3/s5232686/.local/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: blue in /home3/s5232686/.local/lib/python3.10/site-packages (0.9.1)\n",
      "Requirement already satisfied: sentencepiece in /home3/s5232686/.local/lib/python3.10/site-packages (0.2.0)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: requests in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home3/s5232686/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home3/s5232686/.local/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home3/s5232686/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home3/s5232686/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home3/s5232686/.local/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: absl-py in /home3/s5232686/.local/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /home3/s5232686/.local/lib/python3.10/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home3/s5232686/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home3/s5232686/.local/lib/python3.10/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home3/s5232686/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home3/s5232686/.local/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /home3/s5232686/.local/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: psutil in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from peft) (1.0.1)\n",
      "Requirement already satisfied: black==22.1.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from blue) (22.1.0)\n",
      "Requirement already satisfied: flake8<5.0.0,>=3.8 in /home3/s5232686/.local/lib/python3.10/site-packages (from blue) (4.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from black==22.1.0->blue) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from black==22.1.0->blue) (2.4.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from black==22.1.0->blue) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from black==22.1.0->blue) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home3/s5232686/.local/lib/python3.10/site-packages (from black==22.1.0->blue) (1.0.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from flake8<5.0.0,>=3.8->blue) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from flake8<5.0.0,>=3.8->blue) (2.8.0)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from flake8<5.0.0,>=3.8->blue) (2.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home3/s5232686/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home3/s5232686/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home3/s5232686/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.15.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home3/s5232686/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: joblib in /cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/intel/icelake/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home3/s5232686/.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate rouge_score torch matplotlib peft bert-score blue sentencepiece seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available to use\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Enables dynamic GPU memory allocation with expandable segments to reduce fragmentation and improve memory utilization\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using GPUs\n",
    "\n",
    "set_seed(4242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RbQDztnp1SAc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['article', 'highlights', 'id'],\n",
      "    num_rows: 287113\n",
      "})\n",
      "Dataset({\n",
      "    features: ['article', 'highlights', 'id'],\n",
      "    num_rows: 11490\n",
      "})\n",
      "Dataset({\n",
      "    features: ['article', 'highlights', 'id'],\n",
      "    num_rows: 13368\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "ds.keys()\n",
    "\n",
    "print(ds['train'])\n",
    "print(ds['test'])\n",
    "print(ds['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "IwGYoTiqDADk",
    "outputId": "4d4a8a5e-cb81-4c01-b468-72a929fa1b79"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of article lengths in the train set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "article_lengths = [len(article.split()) for article in ds['train']['article']]  \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(article_lengths, bins=50, color='skyblue', edgecolor='black', alpha=0.8, range=(0,2000))\n",
    "\n",
    "plt.xlabel('Article Length', fontsize=14, fontweight='normal') \n",
    "plt.ylabel('Frequency', fontsize=14, fontweight='normal')\n",
    "plt.title('Distribution of Article Lengths', fontsize=16, fontweight='normal')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of highlit lengths in the train set\n",
    "\n",
    "article_lengths = [len(article.split()) for article in ds['train']['highlights']] \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(article_lengths, bins=50, color='skyblue', edgecolor='black', alpha=0.8, range=(0,150))\n",
    "\n",
    "\n",
    "plt.xlabel('Highlights Length', fontsize=14, fontweight='normal') \n",
    "plt.ylabel('Frequency', fontsize=14, fontweight='normal')\n",
    "plt.title('Distribution of Highlights Lengths', fontsize=16, fontweight='normal')\n",
    "\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fU4N55XZ7CVI"
   },
   "outputs": [],
   "source": [
    "# Select a subset of the data \n",
    "\n",
    "train_dataset = ds[\"train\"].select(range(20000))\n",
    "\n",
    "val_dataset = ds[\"validation\"].select(range(750))\n",
    "\n",
    "test_dataset = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an test index to choose which index of the test set to display the summary for\n",
    "\n",
    "TEST_INDEX = 5\n",
    "model_name = \"t5-base\"\n",
    "prefix = \"Provide a detailed an concise summary of this article: \" # used as the instructional prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "_mPSXj5q7L7f",
    "outputId": "7cb780cf-72bf-40fc-8488-10df43957b25"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeef5cbfef940109e5b3cc6fa864783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "# Load the T5 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = [prefix + article for article in examples['article']]\n",
    "    model_inputs = tokenizer(inputs, max_length=1500, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples['highlights'], max_length=200, truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aowRTBvW1u5S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "# NOT NECESSARY TO RUN ----------------------------\n",
    "\n",
    "#print labels of tokenized_train\n",
    "print(tokenized_train[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47035.48689\n",
      "63.63 739.203 638 57\n"
     ]
    }
   ],
   "source": [
    "# NOT NECESSARY TO RUN ----------------------------\n",
    "\n",
    "# Inspecting the sizes of thi inputs and outputs to the tast\n",
    "avg_input_size = sum(len(i['input_ids']) for i in tokenized_train)/len(tokenized_train['input_ids'])\n",
    "first_input_size = len(tokenized_train[0]['input_ids'])\n",
    "\n",
    "avg_output_size = sum(len(i['labels']) for i in tokenized_train)/len(tokenized_train['labels'])\n",
    "first_output_size = len(tokenized_train[0]['labels'])\n",
    "\n",
    "print(avg_output_size*avg_input_size)\n",
    "print(avg_output_size, avg_input_size, first_input_size, first_output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collator and Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4TTp74NPCY-F"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Initialize the data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns from the tokenized sets\n",
    "tokenized_train = tokenized_train.remove_columns([\"highlights\", \"article\", \"id\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"highlights\", \"article\", \"id\"])\n",
    "tokenized_val = tokenized_val.remove_columns([\"highlights\", \"article\", \"id\"])\n",
    "\n",
    "# Check if removing columns was successful\n",
    "print(tokenized_test.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset columns to PyTorch tensors for efficient model input with 'input_ids', 'attention_mask', and 'labels' fields\n",
    "\n",
    "# For training dataset\n",
    "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# For val dataset\n",
    "tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# For testing dataset\n",
    "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Evaluation Metrics for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mrtC3IPACnr8"
   },
   "outputs": [],
   "source": [
    "# Import evaluation metric\n",
    "\n",
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "# Apply smoothing to BLEU score to handle cases with rare or unmatched n-grams.\n",
    "smoothing_function = SmoothingFunction()\n",
    "\n",
    "def compute_metrics_train(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE scores\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    # Add BLEU score\n",
    "    bleu_scores = []\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        reference_tokens = tokenizer.tokenize(label)\n",
    "        generated_tokens = tokenizer.tokenize(pred)\n",
    "        bleu_score = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smoothing_function.method1)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    \n",
    "    result[\"bleu\"] = np.mean(bleu_scores)\n",
    "\n",
    "    # Add BERTScore (F1)\n",
    "    P, R, F1 = bert_score(decoded_preds, decoded_labels, lang=\"en\", rescale_with_baseline=True)\n",
    "    result[\"bert_f1\"] = np.mean(F1.numpy())\n",
    "\n",
    "    # Generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for tracking system metrics during training \n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def get_gpu_memory_usage():\n",
    "    # Run nvidia-smi to get both used and total memory\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-gpu=memory.used,memory.total\", \"--format=csv,nounits,noheader\"],\n",
    "        stdout=subprocess.PIPE\n",
    "    )\n",
    "    used_memory, total_memory = result.stdout.decode(\"utf-8\").strip().split(\"\\n\")[0].split(\", \")\n",
    "\n",
    "    return int(used_memory), int(total_memory)\n",
    "\n",
    "def track_performance(model_type):\n",
    "    process = psutil.Process(os.getpid())\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    # Track memory and time\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)\n",
    "    gpu_memory_used, gpu_memory_total = get_gpu_memory_usage()\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_elapsed = end_time - start_time\n",
    "\n",
    "    print(f\"{model_type} - Time taken: {time_elapsed:.2f} seconds\")\n",
    "    print(f\"{model_type} - CPU Memory usage: {memory_usage:.2f} MB\")\n",
    "    print(f\"{model_type} - GPU Memory usage: {gpu_memory_used} MB / {gpu_memory_total} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions for loading, generating summaries and testing \n",
    "\n",
    "def load_base_model(model_name):\n",
    "    config = T5Config.from_pretrained(model_name)\n",
    "\n",
    "    config.task_specific_params['summarization']['max_length'] = 200\n",
    "\n",
    "    base_model = T5ForConditionalGeneration.from_pretrained(model_name, config=config)\n",
    "    \n",
    "    base_model.to(device)\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "def generate_summary(example, model, peft, custom_tokenizer=tokenizer):\n",
    "    input_text = prefix + example[\"article\"]\n",
    "    input_ids = custom_tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1500, truncation=True).to(device)\n",
    "    if peft:\n",
    "        model.eval()  # Ensure that the model uses the correct generation method with PEFT (LoRA)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(input_ids=input_ids, max_new_tokens=200)\n",
    "    else:       \n",
    "        output = model.generate(input_ids, max_new_tokens = 200)\n",
    "    summary = custom_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def compute_metrics_test(example, model, peft=False):\n",
    "    input_ids = example['input_ids'].to(device)  # Move input_ids to the same device as the model\n",
    "    labels = example['labels'].to(device)  # Move labels to the same device as well\n",
    "\n",
    "    input_ids = input_ids.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Generate the summary using model.generate()\n",
    "    if peft:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(input_ids=input_ids, max_new_tokens=200)\n",
    "    else: \n",
    "        generated_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_length=200,\n",
    "            num_beams=1,\n",
    "        )\n",
    "\n",
    "    decoded_pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "    labels = labels.cpu().numpy()\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_label = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_result = rouge.compute(predictions=[decoded_pred], references=[decoded_label], use_stemmer=True)\n",
    "\n",
    "    # Compute BERTScore (only F1)\n",
    "    _, _, F1 = bert_score([decoded_pred], [decoded_label], lang='en', rescale_with_baseline=True)\n",
    "\n",
    "    # Compute BLEU score\n",
    "    # Tokenize the generated and reference summaries\n",
    "    reference_tokens = tokenizer.tokenize(decoded_label)\n",
    "    generated_tokens = tokenizer.tokenize(decoded_pred)\n",
    "        \n",
    "    bleu_score = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smoothing_function.method1)\n",
    "\n",
    "    return {\n",
    "        'rouge': rouge_result,\n",
    "        'bert_f1': F1.item(),  # Return only F1 score\n",
    "        'bleu': bleu_score  # Return BLEU score\n",
    "    }\n",
    "    \n",
    "def evaluate_model(model, peft=False):\n",
    "    # Initialize accumulators for each ROUGE metric, BERT F1 score, and BLEU score\n",
    "    rouge1_total, rouge2_total, rougel_total = 0, 0, 0\n",
    "    bert_f1_total = 0\n",
    "    bleu_total = 0\n",
    "    num_examples = 100  # Adjust as needed\n",
    "\n",
    "    # Loop through the test examples and accumulate the scores\n",
    "    for i in range(num_examples):\n",
    "        example = tokenized_test[i]  # Get one example from the dataset\n",
    "        scores = compute_metrics_test(example, model, peft)  # Get the ROUGE and BERT scores\n",
    "        \n",
    "        # Accumulate the ROUGE scores\n",
    "        rouge1_total += scores['rouge']['rouge1']\n",
    "        rouge2_total += scores['rouge']['rouge2']\n",
    "        rougel_total += scores['rouge']['rougeL']\n",
    "\n",
    "        # Accumulate BERT F1 scores\n",
    "        bert_f1_total += scores['bert_f1']\n",
    "\n",
    "        # Accumulate BLEU scores\n",
    "        bleu_total += scores['bleu']\n",
    "\n",
    "    # Compute the averages\n",
    "    rouge1_avg = rouge1_total / num_examples\n",
    "    rouge2_avg = rouge2_total / num_examples\n",
    "    rougel_avg = rougel_total / num_examples\n",
    "    bert_f1_avg = bert_f1_total / num_examples\n",
    "    bleu_avg = bleu_total / num_examples\n",
    "    \n",
    "    return rouge1_avg, rouge2_avg, rougel_avg, bert_f1_avg, bleu_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article:\n",
      " (CNN)He's a blue chip college basketball recruit. She's a high school freshman with Down syndrome. At first glance Trey Moses and Ellie Meredith couldn't be more different. But all that changed Thursday when Trey asked Ellie to be his prom date. Trey -- a star on Eastern High School's basketball team in Louisville, Kentucky, who's headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern's prom. So why is he taking Ellie instead? \"She's great... she listens and she's easy to talk to\" he said. Trey made the prom-posal (yes, that's what they are calling invites to prom these days) in the gym during Ellie's P.E. class. Trina Helson, a teacher at Eastern, alerted the school's newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral. She wasn't surpristed by Trey's actions. \"That's the kind of person Trey is,\" she said. To help make sure she said yes, Trey entered the gym armed with flowers and a poster that read \"Let's Party Like it's 1989,\" a reference to the latest album by Taylor Swift, Ellie's favorite singer. Trey also got the OK from Ellie's parents the night before via text. They were thrilled. \"You just feel numb to those moments raising a special needs child,\"  said Darla Meredith, Ellie's mom. \"You first feel the need to protect and then to overprotect.\" Darla Meredith said Ellie has struggled with friendships since elementary school, but a special program at Eastern called Best Buddies had made things easier for her. She said Best Buddies cultivates friendships between students with and without developmental disabilities and prevents students like Ellie from feeling isolated and left out of social functions. \"I guess around middle school is when kids started to care about what others thought,\" she said, but \"this school, this year has been a relief.\" Trey's future coach at Ball State, James Whitford, said he felt great about the prom-posal, noting that Trey, whom he's known for a long time, often works with other kids . Trey's mother, Shelly Moses, was also proud of her son. \"It's exciting to bring awareness to a good cause,\" she said. \"Trey has worked pretty hard, and he's a good son.\" Both Trey and Ellie have a lot of planning to do. Trey is looking to take up special education as a college major, in addition to playing basketball in the fall. As for Ellie, she can't stop thinking about prom. \"Ellie can't wait to go dress shopping\" her mother said. \"Because I've only told about a million people!\" Ellie interjected.\n",
      "\n",
      "Reference Summary (Highlights):\n",
      " College-bound basketball star asks girl with Down syndrome to high school prom .\n",
      "Pictures of the two during the \"prom-posal\" have gone viral .\n",
      "\n",
      "Generated Summary:\n",
      " \"that's the kind of person Trey is,\" says a teacher at eastern high school . \"it's exciting to bring awareness to a good cause,\" says the mother of Ellie's daughter . \"the prom-posal was a great opportunity,\" says a teacher at the school .\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "base_model = load_base_model(model_name)\n",
    "\n",
    "example = test_dataset[TEST_INDEX]  # Get one example from the dataset\n",
    "summary = generate_summary(example, base_model, peft=False)  # Generate summary\n",
    "\n",
    "# Print the input article, reference summary, and generated summary\n",
    "print(\"Original Article:\\n\", example['article'])\n",
    "print(\"\\nReference Summary (Highlights):\\n\", example['highlights'])\n",
    "print(\"\\nGenerated Summary:\\n\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged ROUGE-1: 0.4400\n",
      "Averaged ROUGE-2: 0.1727\n",
      "Averaged ROUGE-L: 0.2904\n",
      "Averaged BERT F1: 0.3113\n",
      "Averaged BLEU: 0.1501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bert_score import score as bert_score  # Import BERTScore\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothing_function = SmoothingFunction()\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "base_model.to(device)\n",
    "\n",
    "rouge1_avg, rouge2_avg, rougel_avg, bert_f1_avg, bleu_avg = evaluate_model(base_model)\n",
    "\n",
    "# Print the averaged scores\n",
    "print(f\"Averaged ROUGE-1: {rouge1_avg:.4f}\")\n",
    "print(f\"Averaged ROUGE-2: {rouge2_avg:.4f}\")\n",
    "print(f\"Averaged ROUGE-L: {rougel_avg:.4f}\")\n",
    "print(f\"Averaged BERT F1: {bert_f1_avg:.4f}\")\n",
    "print(f\"Averaged BLEU: {bleu_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, T5Config, T5ForConditionalGeneration, get_linear_schedule_with_warmup\n",
    "\n",
    "# Loading the base model that will be fine tuned\n",
    "full_tuned_model = load_base_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and logging system metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Specify the training args for full finetuning on the T5-base model \n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "WEIGHT_DECAY= 0.001\n",
    "LEARNING_R = 5e-5\n",
    "\n",
    "num_training_steps = len(tokenized_train) // (2 * 8) * 2  # Assuming 2 epochs and batch_size=2, ga = 8\n",
    "WARMUP_STEPS = int(num_training_steps * 0.1) \n",
    "\n",
    "optimizer = AdamW(\n",
    "    full_tuned_model.parameters(),\n",
    "    lr=LEARNING_R,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    betas=(0.9, 0.999),  \n",
    "    eps=1e-8             \n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "EVAL_STEPS = int(len(tokenized_train) // (2 * 8 * 5)) # batch_size * ga-steps * how many times per epoch to evaluate (5 here)\n",
    "LOG_STEPS = EVAL_STEPS // 5\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"t5base\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps = EVAL_STEPS, \n",
    "    save_steps = EVAL_STEPS, \n",
    "    logging_steps = LOG_STEPS,\n",
    "    learning_rate=LEARNING_R,\n",
    "    per_device_train_batch_size=6,  # Increasing might cause CUDA out of memory\n",
    "    per_device_eval_batch_size=6,  # Increasing might cause CUDA out of memory\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True, \n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,  # Load the best model after training\n",
    "    warmup_steps=WARMUP_STEPS,  # Include warmup steps\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=full_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_train,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/s5232686/.local/lib/python3.10/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4/82 00:05 < 03:43, 0.35 it/s, Epoch 0.07/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# usage for T5 (set argument to model_name)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrack_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFull Fine-Tuned: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [18], line 118\u001b[0m, in \u001b[0;36mtrack_performance\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m    114\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Your model training or inference code here\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# For LoRA setup, include the relevant training code\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Track memory and time\u001b[39;00m\n\u001b[1;32m    121\u001b[0m memory_usage \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2393\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine tuning and tracking system metrics\n",
    "track_performance(\"Full Fine-Tuned: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./first-trained-t5base-token/tokenizer_config.json',\n",
       " './first-trained-t5base-token/special_tokens_map.json',\n",
       " './first-trained-t5base-token/spiece.model',\n",
       " './first-trained-t5base-token/added_tokens.json',\n",
       " './first-trained-t5base-token/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "model.save_pretrained(\"./first-full-t5base-idk\")\n",
    "tokenizer.save_pretrained(\"./first-trained-t5base-token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article:\n",
      " (CNN)He's a blue chip college basketball recruit. She's a high school freshman with Down syndrome. At first glance Trey Moses and Ellie Meredith couldn't be more different. But all that changed Thursday when Trey asked Ellie to be his prom date. Trey -- a star on Eastern High School's basketball team in Louisville, Kentucky, who's headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern's prom. So why is he taking Ellie instead? \"She's great... she listens and she's easy to talk to\" he said. Trey made the prom-posal (yes, that's what they are calling invites to prom these days) in the gym during Ellie's P.E. class. Trina Helson, a teacher at Eastern, alerted the school's newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral. She wasn't surpristed by Trey's actions. \"That's the kind of person Trey is,\" she said. To help make sure she said yes, Trey entered the gym armed with flowers and a poster that read \"Let's Party Like it's 1989,\" a reference to the latest album by Taylor Swift, Ellie's favorite singer. Trey also got the OK from Ellie's parents the night before via text. They were thrilled. \"You just feel numb to those moments raising a special needs child,\"  said Darla Meredith, Ellie's mom. \"You first feel the need to protect and then to overprotect.\" Darla Meredith said Ellie has struggled with friendships since elementary school, but a special program at Eastern called Best Buddies had made things easier for her. She said Best Buddies cultivates friendships between students with and without developmental disabilities and prevents students like Ellie from feeling isolated and left out of social functions. \"I guess around middle school is when kids started to care about what others thought,\" she said, but \"this school, this year has been a relief.\" Trey's future coach at Ball State, James Whitford, said he felt great about the prom-posal, noting that Trey, whom he's known for a long time, often works with other kids . Trey's mother, Shelly Moses, was also proud of her son. \"It's exciting to bring awareness to a good cause,\" she said. \"Trey has worked pretty hard, and he's a good son.\" Both Trey and Ellie have a lot of planning to do. Trey is looking to take up special education as a college major, in addition to playing basketball in the fall. As for Ellie, she can't stop thinking about prom. \"Ellie can't wait to go dress shopping\" her mother said. \"Because I've only told about a million people!\" Ellie interjected.\n",
      "\n",
      "Reference Summary (Highlights):\n",
      " College-bound basketball star asks girl with Down syndrome to high school prom .\n",
      "Pictures of the two during the \"prom-posal\" have gone viral .\n",
      "\n",
      "Generated Summary:\n",
      " a special needs student is invited to take his girlfriend to a prom . Trey Moses was a star on the basketball team at Eastern . he's a college basketball recruit .\n"
     ]
    }
   ],
   "source": [
    "# Evalutating the fully fine tuned model\n",
    "\n",
    "import torch\n",
    "\n",
    "full_tuned_model.to(device)\n",
    "\n",
    "# Example usage:\n",
    "example = test_dataset[TEST_INDEX]  # Get one example from the dataset\n",
    "summary = generate_summary(example, full_tuned_model, peft=False)  # Generate summary\n",
    "\n",
    "# Print the input article, reference summary, and generated summary\n",
    "print(\"Original Article:\\n\", example['article'])\n",
    "print(\"\\nReference Summary (Highlights):\\n\", example['highlights'])\n",
    "print(\"\\nGenerated Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged ROUGE-1: 0.3295\n",
      "Averaged ROUGE-2: 0.1134\n",
      "Averaged ROUGE-L: 0.2701\n",
      "Averaged BERT F1: 0.2511\n",
      "Averaged BLEU: 0.0970\n"
     ]
    }
   ],
   "source": [
    "# Evalutating the fully fine tuned model\n",
    "\n",
    "import numpy as np\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothing_function = SmoothingFunction()\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "full_tuned_model.to(device)\n",
    "\n",
    "rouge1_avg, rouge2_avg, rougel_avg, bert_f1_avg, bleu_avg = evaluate_model(full_tuned_model)\n",
    "\n",
    "# Print the averaged scores\n",
    "print(f\"Averaged ROUGE-1: {rouge1_avg:.4f}\")\n",
    "print(f\"Averaged ROUGE-2: {rouge2_avg:.4f}\")\n",
    "print(f\"Averaged ROUGE-L: {rougel_avg:.4f}\")\n",
    "print(f\"Averaged BERT F1: {bert_f1_avg:.4f}\")\n",
    "print(f\"Averaged BLEU: {bleu_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Efficient Fine-Tuning (PEFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training and LoRa configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, T5Config, T5ForConditionalGeneration\n",
    "\n",
    "# Load the base model for LoRa fine tuning\n",
    "lora_model = load_base_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 224,673,024 || trainable%: 0.7876\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRa settings\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=32,  \n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA configuration\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Training args for fine tuning the T5-base using LoRa\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "WEIGHT_DECAY= 0.1  # try 0.1\n",
    "LEARNING_R = 1e-5\n",
    "\n",
    "num_training_steps = len(tokenized_train) // (2 * 6) * 2  # Assuming 2 epochs and batch_size=2, ga = 8\n",
    "WARMUP_STEPS = int(num_training_steps * 0.1) # was 0.1\n",
    "\n",
    "optimizer = AdamW(\n",
    "    lora_model.parameters(),\n",
    "    lr=LEARNING_R,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    betas=(0.9, 0.999),  \n",
    "    eps=1e-8             \n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "EVAL_STEPS = int(len(tokenized_train) // (6 * 2 * 5)) # batch_size * ga-steps * how many times per epoch to evaluate (5 here)\n",
    "LOG_STEPS = EVAL_STEPS // 5\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"t5base\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps = EVAL_STEPS, \n",
    "    save_steps = EVAL_STEPS, \n",
    "    logging_steps = LOG_STEPS,\n",
    "    learning_rate=LEARNING_R,\n",
    "    per_device_train_batch_size=6,  # DO NOT CHANGE (BESTLY)\n",
    "    per_device_eval_batch_size=6,  # DO NOT CHANGE (BESTLY)\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True, \n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_accumulation_steps=2,\n",
    "    load_best_model_at_end=True,  # Load the best model after training\n",
    "    warmup_steps=WARMUP_STEPS,  # Include warmup steps\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_train,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and logging system metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1667' max='1667' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1667/1667 24:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Bert F1</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>1.886400</td>\n",
       "      <td>1.971725</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.165300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>1.633200</td>\n",
       "      <td>1.745763</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>1.541500</td>\n",
       "      <td>1.682871</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1332</td>\n",
       "      <td>1.531300</td>\n",
       "      <td>1.676130</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>1.549300</td>\n",
       "      <td>1.675682</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/s5232686/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home3/s5232686/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home3/s5232686/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home3/s5232686/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home3/s5232686/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA - Time taken: 1494.58 seconds\n",
      "LoRA - CPU Memory usage: 4025.35 MB\n",
      "LoRA - GPU Memory usage: 21925 MB / 40960 MB\n"
     ]
    }
   ],
   "source": [
    "# LoRa finetuning and tracking system metrics\n",
    "track_performance(\"LoRA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "EuHjKjam918h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./try-token/tokenizer_config.json',\n",
       " './try-token/special_tokens_map.json',\n",
       " './try-token/spiece.model',\n",
       " './try-token/added_tokens.json',\n",
       " './try-token/tokenizer.json')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving\n",
    "lora_model.save_pretrained(\"./try\")\n",
    "tokenizer.save_pretrained(\"./try-token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/None/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1339\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1854\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1746\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1746\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1666\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1666\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1675\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:364\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 364\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:388\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    387\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 388\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6723b143-7f0e985058cc438471ee1ded;458dde48-71c6-468a-ba16-065be9c67737)\n\nRepository Not Found for url: https://huggingface.co/None/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loraa_model \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./try\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tokenizer_test \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./try-token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:3408\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3407\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 3408\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3418\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3419\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_auto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_auto_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3420\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3424\u001b[0m     \u001b[38;5;66;03m# In case one passes a config to `from_pretrained` + \"attn_implementation\"\u001b[39;00m\n\u001b[1;32m   3425\u001b[0m     \u001b[38;5;66;03m# override the `_attn_implementation` attribute to `attn_implementation` of the kwargs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3429\u001b[0m     \u001b[38;5;66;03m# we pop attn_implementation from the kwargs but this handles the case where users\u001b[39;00m\n\u001b[1;32m   3430\u001b[0m     \u001b[38;5;66;03m# passes manually the config to `from_pretrained`.\u001b[39;00m\n\u001b[1;32m   3431\u001b[0m     config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:541\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 541\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    543\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:570\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:629\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "loraa_model = T5ForConditionalGeneration.from_pretrained(\"./try\")\n",
    "tokenizer_test = AutoTokenizer.from_pretrained(\"./try-token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article:\n",
      " (CNN)He's a blue chip college basketball recruit. She's a high school freshman with Down syndrome. At first glance Trey Moses and Ellie Meredith couldn't be more different. But all that changed Thursday when Trey asked Ellie to be his prom date. Trey -- a star on Eastern High School's basketball team in Louisville, Kentucky, who's headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern's prom. So why is he taking Ellie instead? \"She's great... she listens and she's easy to talk to\" he said. Trey made the prom-posal (yes, that's what they are calling invites to prom these days) in the gym during Ellie's P.E. class. Trina Helson, a teacher at Eastern, alerted the school's newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral. She wasn't surpristed by Trey's actions. \"That's the kind of person Trey is,\" she said. To help make sure she said yes, Trey entered the gym armed with flowers and a poster that read \"Let's Party Like it's 1989,\" a reference to the latest album by Taylor Swift, Ellie's favorite singer. Trey also got the OK from Ellie's parents the night before via text. They were thrilled. \"You just feel numb to those moments raising a special needs child,\"  said Darla Meredith, Ellie's mom. \"You first feel the need to protect and then to overprotect.\" Darla Meredith said Ellie has struggled with friendships since elementary school, but a special program at Eastern called Best Buddies had made things easier for her. She said Best Buddies cultivates friendships between students with and without developmental disabilities and prevents students like Ellie from feeling isolated and left out of social functions. \"I guess around middle school is when kids started to care about what others thought,\" she said, but \"this school, this year has been a relief.\" Trey's future coach at Ball State, James Whitford, said he felt great about the prom-posal, noting that Trey, whom he's known for a long time, often works with other kids . Trey's mother, Shelly Moses, was also proud of her son. \"It's exciting to bring awareness to a good cause,\" she said. \"Trey has worked pretty hard, and he's a good son.\" Both Trey and Ellie have a lot of planning to do. Trey is looking to take up special education as a college major, in addition to playing basketball in the fall. As for Ellie, she can't stop thinking about prom. \"Ellie can't wait to go dress shopping\" her mother said. \"Because I've only told about a million people!\" Ellie interjected.\n",
      "\n",
      "Reference Summary (Highlights):\n",
      " College-bound basketball star asks girl with Down syndrome to high school prom .\n",
      "Pictures of the two during the \"prom-posal\" have gone viral .\n",
      "\n",
      "Generated Summary:\n",
      " Eastern High School basketball star Trey Moses asks Ellie Meredith to be his prom date . Ellie is a high school freshman with Down syndrome . Trey's mom says he's a good son and has worked hard to help her .\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the LoRa fine tuned model\n",
    "import torch\n",
    "\n",
    "lora_model.to(device)\n",
    "\n",
    "# Example usage:\n",
    "example = test_dataset[TEST_INDEX]  # Get one example from the dataset\n",
    "summary = generate_summary(example, lora_model, peft=True)  # Generate summary\n",
    "\n",
    "# Print the input article, reference summary, and generated summary\n",
    "print(\"Original Article:\\n\", example['article'])\n",
    "print(\"\\nReference Summary (Highlights):\\n\", example['highlights'])\n",
    "print(\"\\nGenerated Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged ROUGE-1: 0.3530\n",
      "Averaged ROUGE-2: 0.1488\n",
      "Averaged ROUGE-L: 0.2654\n",
      "Averaged BERT F1: 0.2963\n",
      "Averaged BLEU: 0.1444\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the LoRa fine tuned model\n",
    "import numpy as np\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothing_function = SmoothingFunction()\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "lora_model.to(device)\n",
    "\n",
    "rouge1_avg, rouge2_avg, rougel_avg, bert_f1_avg, bleu_avg = evaluate_model(lora_model, peft=True)\n",
    "\n",
    "# Print the averaged scores\n",
    "print(f\"Averaged ROUGE-1: {rouge1_avg:.4f}\")\n",
    "print(f\"Averaged ROUGE-2: {rouge2_avg:.4f}\")\n",
    "print(f\"Averaged ROUGE-L: {rougel_avg:.4f}\")\n",
    "print(f\"Averaged BERT F1: {bert_f1_avg:.4f}\")\n",
    "print(f\"Averaged BLEU: {bleu_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (GPU)",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bc0f3eb18cc4551ab0f3e25dcfc2150": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_72caaeec9aba4be9ae316812e2862c23",
      "style": "IPY_MODEL_592b7532af0e4e789a3847b2fd23fc07",
      "tooltip": ""
     }
    },
    "1301afdabeb4453b95d2e367ef1d0dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_daed54417278429989c6840caaebdbbf",
      "placeholder": "",
      "style": "IPY_MODEL_36946ceb69884a90b1aa9836e9fc4247",
      "value": ""
     }
    },
    "15b0f411b2ae4843b588052b7e6c08c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1763ca6e001945c08958961e285e4863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28731c78c347415f874a0a0b1b2d351e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28ac89fb83274d3b8ee8ffea9f8e7a5e",
      "placeholder": "",
      "style": "IPY_MODEL_e47181a0138148a98bf72437cf849792",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "28ac89fb83274d3b8ee8ffea9f8e7a5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36946ceb69884a90b1aa9836e9fc4247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39fb3927233449c3871b2db51047ad89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad875953785048fbbaba964ca9220e1f",
      "placeholder": "",
      "style": "IPY_MODEL_41feec41a0404931acb1b4d678926376",
      "value": "Login successful"
     }
    },
    "41feec41a0404931acb1b4d678926376": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "422dd36f3b36446780641ad76b89bbf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f833a430294c65b13f9dd4edc54b65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51badf3c70644357841ea732e3270381": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "5496f21ac02e44a4b63f8f5ebf59ce12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57376c4ffe6d497aba6ead0478800d75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1d2c50f7b49476cab7684829d0f403d",
      "placeholder": "",
      "style": "IPY_MODEL_ce2e7dd4b7db43dfb212f7a30c7d9783",
      "value": "Invalid token passed!"
     }
    },
    "592b7532af0e4e789a3847b2fd23fc07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "59e32d0785aa4eacbb521511efcd9657": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fcb959ffca844ba98187380f8360883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "679e9c6b3d0f46edb5bae7ab6faa13a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6894cd74d954897a3423bb833779759",
      "placeholder": "",
      "style": "IPY_MODEL_dab0d03a2907480d80c19fd7e356e37a",
      "value": "Token is valid (permission: fineGrained)."
     }
    },
    "6a97785fd7f449dbbd49097d11be34c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e32d0785aa4eacbb521511efcd9657",
      "placeholder": "",
      "style": "IPY_MODEL_f3df82ef40ee4703951a68f54f77a6f4",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "72caaeec9aba4be9ae316812e2862c23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78275e636f2449b8beb8665b61d28744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aac627f3a5a6496ea61920e903ad76c2"
      ],
      "layout": "IPY_MODEL_51badf3c70644357841ea732e3270381"
     }
    },
    "7f0cb36f989a4cd18d636bd92c18a62b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86afcd301077486198f66cc0ac4a06d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a19b8fbcbbc24f17a0a106f6d3e7923e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aac627f3a5a6496ea61920e903ad76c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9b9d1b0989446a897f46d4efa4b865a",
      "placeholder": "",
      "style": "IPY_MODEL_422dd36f3b36446780641ad76b89bbf2",
      "value": "Invalid token passed!"
     }
    },
    "ad875953785048fbbaba964ca9220e1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af604d6454da4974a3987a3612341e13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47f833a430294c65b13f9dd4edc54b65",
      "placeholder": "",
      "style": "IPY_MODEL_a19b8fbcbbc24f17a0a106f6d3e7923e",
      "value": "Connecting..."
     }
    },
    "b4f4cf6e0f9448e48d8019facc58d241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d80f5fb9c9a147ed90fee503d7104e7e",
      "placeholder": "",
      "style": "IPY_MODEL_d5cdf24ed2304525b8e075b0fa50a0ac",
      "value": "Connecting..."
     }
    },
    "c1d2c50f7b49476cab7684829d0f403d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6894cd74d954897a3423bb833779759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9b9d1b0989446a897f46d4efa4b865a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cded868ab2f541b7a5df37fd86760176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce2e7dd4b7db43dfb212f7a30c7d9783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5cdf24ed2304525b8e075b0fa50a0ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d80f5fb9c9a147ed90fee503d7104e7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dab0d03a2907480d80c19fd7e356e37a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "daed54417278429989c6840caaebdbbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db05389cd79f4ee882194ba50858c1b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e47181a0138148a98bf72437cf849792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4daf0fdd5194f59bc9adbc2d0801d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f0cb36f989a4cd18d636bd92c18a62b",
      "placeholder": "",
      "style": "IPY_MODEL_5fcb959ffca844ba98187380f8360883",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "ea1f02bc47654f25910485890f9625a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15b0f411b2ae4843b588052b7e6c08c8",
      "placeholder": "",
      "style": "IPY_MODEL_5496f21ac02e44a4b63f8f5ebf59ce12",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "ec35c80b3d4840e89026cb3f67c5f5ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cded868ab2f541b7a5df37fd86760176",
      "placeholder": "",
      "style": "IPY_MODEL_86afcd301077486198f66cc0ac4a06d7",
      "value": "Connecting..."
     }
    },
    "f3df82ef40ee4703951a68f54f77a6f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f873edc5a4514508865eb690e662cfcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_1763ca6e001945c08958961e285e4863",
      "style": "IPY_MODEL_db05389cd79f4ee882194ba50858c1b3",
      "value": true
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
